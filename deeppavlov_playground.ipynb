{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeppavlov-playground.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0X5ZeiRyg9r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f134cff-3255-446d-8403-4d9f3b6b33a4"
      },
      "source": [
        "!pip install deeppavlov"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deeppavlov\n",
            "  Downloading deeppavlov-0.17.1-py3-none-any.whl (929 kB)\n",
            "\u001b[K     |████████████████████████████████| 929 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting filelock==3.0.12\n",
            "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 34.8 MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "  Downloading fastapi-0.47.1-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading overrides-2.7.0.tar.gz (4.5 kB)\n",
            "Collecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 43.1 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "  Downloading scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7 MB 43.4 MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "  Downloading pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3 MB 12.0 MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading rusenttokenize-0.0.5-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Collecting pymorphy2-dicts-ru\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 35.5 MB/s \n",
            "\u001b[?25hCollecting pymorphy2==0.8\n",
            "  Downloading pymorphy2-0.8-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.7 MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "  Downloading Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 28.0 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "  Downloading numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "  Downloading sacremoses-0.0.35.tar.gz (859 kB)\n",
            "\u001b[K     |████████████████████████████████| 859 kB 41.9 MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "  Downloading aio_pika-6.4.1-py3-none-any.whl (40 kB)\n",
            "\u001b[K     |████████████████████████████████| 40 kB 20 kB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "  Downloading ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654 kB)\n",
            "\u001b[K     |████████████████████████████████| 654 kB 49.6 MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "  Downloading pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 33.8 MB/s \n",
            "\u001b[?25hCollecting pytz==2019.1\n",
            "  Downloading pytz-2019.1-py2.py3-none-any.whl (510 kB)\n",
            "\u001b[K     |████████████████████████████████| 510 kB 33.0 MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.7\n",
            "  Downloading uvicorn-0.11.7-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "  Downloading pyTelegramBotAPI-3.6.7.tar.gz (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "  Downloading pyOpenSSL-19.1.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting requests==2.22.0\n",
            "  Downloading requests-2.22.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting tqdm==4.62.0\n",
            "  Downloading tqdm-4.62.0-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting prometheus-client==0.7.1\n",
            "  Downloading prometheus_client-0.7.1.tar.gz (38 kB)\n",
            "Collecting uvloop==0.14.0\n",
            "  Downloading uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 44.5 MB/s \n",
            "\u001b[?25hCollecting aiormq<4,>=3.2.0\n",
            "  Downloading aiormq-3.3.1-py3-none-any.whl (28 kB)\n",
            "Collecting yarl\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 47.7 MB/s \n",
            "\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n",
            "  Downloading starlette-0.12.9.tar.gz (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 31.6 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.8\n",
            "  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2021.10.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "  Downloading idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.1.0)\n",
            "Collecting h11<0.10,>=0.8\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*\n",
            "  Downloading httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219 kB)\n",
            "\u001b[K     |████████████████████████████████| 219 kB 45.3 MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "  Downloading websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading pamqp-2.3.0-py2.py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.21)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.10.0.2)\n",
            "Collecting multidict>=4.0\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 48.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: nltk, overrides, prometheus-client, pytelegrambotapi, sacremoses, starlette\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449923 sha256=a516ba29027d08a0e6f1bc19522e7e2ec7985e18f2d03a1d58e63ced42d592e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-py3-none-any.whl size=5605 sha256=c8005b41006b29f56f6c18542d7807cda49ab7e859f25d926b1ccd7ffd78959d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/87/45/bfdacf6c3b8233b6e8d519edcbd1cf297ad5ff5f0bf84bb9c1\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41404 sha256=390dcc3101a2ddbfc2d9a8f1e892445edddd907efd7149a1c273322aef9e818b\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-py3-none-any.whl size=47176 sha256=51461f7f31f66c89fdad10d5e2bc4c6bd4421e883a590119e3e1e268fbf51918\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/7c/54/8eddf2369ef1b9190e2ee6dc2b40df54b6c65529a38790fdd4\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-py3-none-any.whl size=883989 sha256=2b3d4a6f1fb0cc8be5f38768e8681c9a3080fa06e4fa05d8d567837719697a9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/ff/0e/e00ff1e22100702ac8b24e709551ae0fb29db9ffc843510a64\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-py3-none-any.whl size=57251 sha256=2f3ac8ed93ee0cc27670db0aa297868e2ce41474d57569229de960ea73bd8734\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/78/be/f57ed5aed7cd222abdb24e3186b5c9f1074184fcc0a295102b\n",
            "Successfully built nltk overrides prometheus-client pytelegrambotapi sacremoses starlette\n",
            "Installing collected packages: multidict, idna, yarl, pamqp, numpy, websockets, uvloop, tqdm, starlette, requests, pytz, pymorphy2-dicts, pydantic, httptools, h11, dawg-python, cryptography, aiormq, uvicorn, scikit-learn, sacremoses, rusenttokenize, ruamel.yaml, pytelegrambotapi, pyopenssl, pymorphy2-dicts-ru, pymorphy2, prometheus-client, pandas, overrides, nltk, h5py, filelock, fastapi, Cython, aio-pika, deeppavlov\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.62.3\n",
            "    Uninstalling tqdm-4.62.3:\n",
            "      Successfully uninstalled tqdm-4.62.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.12.0\n",
            "    Uninstalling prometheus-client-0.12.0:\n",
            "      Successfully uninstalled prometheus-client-0.12.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.4.0\n",
            "    Uninstalling filelock-3.4.0:\n",
            "      Successfully uninstalled filelock-3.4.0\n",
            "  Attempting uninstall: Cython\n",
            "    Found existing installation: Cython 0.29.24\n",
            "    Uninstalling Cython-0.29.24:\n",
            "      Successfully uninstalled Cython-0.29.24\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.25.3 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.21.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.25.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.22.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.25.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-36.0.0 dawg-python-0.7.2 deeppavlov-0.17.1 fastapi-0.47.1 filelock-3.0.12 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-5.2.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 tqdm-4.62.0 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fBmlEzVzAJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9746ea-dd8c-4031-93ef-fe1665c8b5e4"
      },
      "source": [
        "!wget https://github.com/deepmipt/DeepPavlov/blob/0.17.1/deeppavlov/configs/classifiers/sentiment_sst_conv_bert.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-23 17:02:47--  https://github.com/deepmipt/DeepPavlov/blob/0.17.1/deeppavlov/configs/classifiers/sentiment_sst_conv_bert.json\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘sentiment_sst_conv_bert.json’\n",
            "\n",
            "sentiment_sst_conv_     [ <=>                ] 203.69K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-11-23 17:02:47 (1.99 MB/s) - ‘sentiment_sst_conv_bert.json’ saved [208579]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFBME4ibyYXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702f61db-821e-4c8e-80f2-c3c13ae0338c"
      },
      "source": [
        "!python -m deeppavlov install  'sentiment_sst_conv_bert'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-23 17:02:48.869 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'sentiment_sst_conv_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/classifiers/sentiment_sst_conv_bert.json'\n",
            "Collecting tensorflow==1.15.5\n",
            "  Downloading tensorflow-1.15.5-cp37-cp37m-manylinux2010_x86_64.whl (110.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5 MB 1.3 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 44.1 MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.17.3)\n",
            "Requirement already satisfied: h5py<=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (2.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.42.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (3.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (0.37.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.13.3)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.1.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.18.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.5) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.5) (3.6.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=1fff84a30442919368883b49cee93c0e30dbb3960e01181b7dc63c62f16476f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.7.0\n",
            "    Uninstalling tensorflow-estimator-2.7.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.7.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.7.0\n",
            "    Uninstalling tensorboard-2.7.0:\n",
            "      Successfully uninstalled tensorboard-2.7.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.7.0\n",
            "    Uninstalling tensorflow-2.7.0:\n",
            "      Successfully uninstalled tensorflow-2.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.15.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.6 requires numpy>=1.18.5, but you have numpy 1.18.0 which is incompatible.\n",
            "kapre 0.3.6 requires tensorflow>=2.0.0, but you have tensorflow 1.15.5 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.5 tensorflow-estimator-1.15.1\n",
            "Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n",
            "  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-omqhcn21\n",
            "  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-omqhcn21\n",
            "Building wheels for collected packages: bert-dp\n",
            "  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-dp: filename=bert_dp-1.0-py3-none-any.whl size=23591 sha256=0aa119ec5eb4524de1c415c2a9a15abd7682189fb770e402220be6c3547acb30\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-k7ee8n49/wheels/44/29/b2/ee614cb7f97ba5c2d220029eaede3af4b74331ad31d6e2f4eb\n",
            "Successfully built bert-dp\n",
            "Installing collected packages: bert-dp\n",
            "Successfully installed bert-dp-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tF81xrev0l_j",
        "outputId": "18c58e37-7579-4713-e6fd-cbd447cd03e8"
      },
      "source": [
        "!python -m deeppavlov download  'sentiment_sst_conv_bert'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-23 17:03:34.448 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'sentiment_sst_conv_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/classifiers/sentiment_sst_conv_bert.json'\n",
            "/usr/local/lib/python3.7/dist-packages/cryptography/hazmat/backends/openssl/x509.py:17: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
            "  utils.DeprecatedIn35,\n",
            "2021-11-23 17:03:35.255 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/classifiers/sentiment_sst_bert_v2.tar.gz?config=sentiment_sst_conv_bert to /root/.deeppavlov/models/sentiment_sst_bert_v2.tar.gz\n",
            "100% 401M/401M [00:15<00:00, 25.4MB/s]\n",
            "2021-11-23 17:03:51.823 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/sentiment_sst_bert_v2.tar.gz archive into /root/.deeppavlov/models/classifiers\n",
            "2021-11-23 17:03:57.169 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/datasets/stanfordSentimentTreebank.zip?config=sentiment_sst_conv_bert to /root/.deeppavlov/stanfordSentimentTreebank.zip\n",
            "100% 7.26M/7.26M [00:01<00:00, 7.17MB/s]\n",
            "2021-11-23 17:03:58.949 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/stanfordSentimentTreebank.zip archive into /root/.deeppavlov/downloads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yQHgEc51Rn6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa778c05-01e3-47b0-8a81-2fea329eb9bc"
      },
      "source": [
        "!python -m deeppavlov predict 'sentiment_sst_conv_bert' -f 'predict_text.txt'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-23 17:04:00.251 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'sentiment_sst_conv_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/classifiers/sentiment_sst_conv_bert.json'\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/__main__.py\", line 4, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/deep.py\", line 128, in main\n",
            "    predict_on_stream(pipeline_config_path, args.batch_size, args.file_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/deeppavlov/core/commands/infer.py\", line 107, in predict_on_stream\n",
            "    f = open(file_path, encoding='utf8')\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'predict_text.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiP5asXaKq3k",
        "outputId": "ba0fb7e1-a578-439d-fa95-9350553f438e"
      },
      "source": [
        "# tg token 2115383453:AAEIcUSa_R1VP_jomKSlb8bUxOrsYb1vID0\n",
        "# If you want to use a model in the bot just pass your token\n",
        "!python -m deeppavlov telegram 'sentiment_sst_conv_bert' -t 2115383453:AAEIcUSa_R1VP_jomKSlb8bUxOrsYb1vID0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-23 17:04:01.417 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'sentiment_sst_conv_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/classifiers/sentiment_sst_conv_bert.json'\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "2021-11-23 17:04:04.647 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/classifiers/sentiment_sst_bert_v2/classes.dict]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:84: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "2021-11-23 17:04:04.667109: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2021-11-23 17:04:04.670414: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2021-11-23 17:04:04.670682: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d0d19d0bc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-11-23 17:04:04.670718: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:161: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:234: The name tf.train.AdadeltaOptimizer is deprecated. Please use tf.compat.v1.train.AdadeltaOptimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:127: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_classifier.py:92: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:50: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-11-23 17:04:24.439 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/classifiers/sentiment_sst_bert_v2/model]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2021-11-23 17:04:25.656 INFO in 'deeppavlov.utils.connector.bot'['bot'] at line 72: Bot initiated\n"
          ]
        }
      ]
    }
  ]
}